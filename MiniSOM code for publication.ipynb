{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native libraries\n",
    "import os\n",
    "import math\n",
    "import glob\n",
    "# Essential Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler,MaxAbsScaler\n",
    "# Algorithms\n",
    "from minisom import MiniSom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa0a82",
   "metadata": {},
   "source": [
    "Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = pd.read_csv(r'')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7ea44",
   "metadata": {},
   "source": [
    "Calculate time from frame number, trim first 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade624fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df['time'] = (all_data_df['frame'] - 1) * 20\n",
    "print(all_data_df['time'].unique())\n",
    "\n",
    "# trim to min_time and max_time\n",
    "min_time = 0\n",
    "max_time = 900\n",
    "all_data_df = all_data_df[(all_data_df['time'] >= min_time) & (all_data_df['time'] <= max_time)]\n",
    "print(all_data_df['time'].unique())\n",
    "\n",
    "print(f\"all_data_df rows: {len(all_data_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ca8e0",
   "metadata": {},
   "source": [
    "Remove cells farther than 200 um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove cells farther than 200 um\n",
    "all_data_df = all_data_df[all_data_df['dmap_um_laser'] <= 200]\n",
    "print(f\"all_data_df rows after removing cells farther than 200 um: {len(all_data_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9edc5",
   "metadata": {},
   "source": [
    "Drop all cells that don't appear in every frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dceed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the expected number of frames for each cell\n",
    "\n",
    "expected_frames = (max_time - min_time) // 20 + 1\n",
    "\n",
    "# Keep only unique_cell_id groups that appear in every frame\n",
    "\n",
    "all_data_df = all_data_df.groupby('unique_cell_id').filter(lambda x: len(x) == expected_frames)\n",
    "\n",
    "print(f\"all_data_df rows: {len(all_data_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d073e0",
   "metadata": {},
   "source": [
    "Get normalized green/red deltaF/F0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3617589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df['greenperred'] = all_data_df['intensity_mean_GFP'] / all_data_df['intensity_mean_RFP']\n",
    "\n",
    "display(all_data_df[[ 'intensity_mean_GFP', 'intensity_mean_RFP', 'greenperred']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6721862",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_max_frame = 15\n",
    "\n",
    "# Get greenperred baseline values between 0 and baseline_max_frame\n",
    "\n",
    "baseline_df = all_data_df[all_data_df['frame'] <= baseline_max_frame].copy()\n",
    "baseline_df['greenperred_F0'] = baseline_df.groupby('unique_cell_id')['greenperred'].transform('mean')\n",
    "baseline_df = baseline_df[['unique_cell_id', 'greenperred_F0']].drop_duplicates()\n",
    "\n",
    "# Assign the baseline values to the original DataFrame\n",
    "\n",
    "all_data_df['greenperred_F0'] = all_data_df['unique_cell_id'].map(baseline_df.set_index('unique_cell_id')['greenperred_F0'])\n",
    "\n",
    "# Calculate delataF for greenperred\n",
    "\n",
    "all_data_df['greenperred_dF'] = all_data_df['greenperred'] - all_data_df['greenperred_F0']\n",
    "\n",
    "# Calculate deltaF/F0 for greenperred\n",
    "all_data_df['gpr_dF/F0'] = all_data_df['greenperred_dF'] / all_data_df['greenperred_F0']\n",
    "\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "display(all_data_df[['unique_cell_id', 'time', 'greenperred', 'greenperred_F0', 'gpr_dF/F0']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ac221",
   "metadata": {},
   "source": [
    "Set is_iso and is_itga indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131713e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each cell check if unique_cell_id contains 'itga' -> set is_itga to True, else False\n",
    "all_data_df['is_itga'] = all_data_df['unique_cell_id'].str.contains('x1172')\n",
    "#for each cell check if unique_cell_id contains 'iso' -> set is_iso to True, else False\n",
    "all_data_df['is_iso'] = all_data_df['unique_cell_id'].str.contains('iso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd3b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df[[\"is_iso\",\"is_itga\",\"unique_cell_id\"]].drop_duplicates().groupby([\"is_iso\",\"is_itga\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638e17ed",
   "metadata": {},
   "source": [
    "Check if there are NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f080ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if there are NaN values in gpr_dF/F0\n",
    "nan_gpr_dF_F0 = all_data_df[all_data_df['gpr_dF/F0'].isna()]\n",
    "print(f\"Number of NaN values in gpr_dF/F0: {len(nan_gpr_dF_F0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85af02",
   "metadata": {},
   "source": [
    "Filter cells: (after wounding) 0.5<= dF/F0 <10 (at any point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb4cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all unique_cell_id values where gpr_dF/F0 > 10 at any timepoint\n",
    "\n",
    "cells_to_remove = all_data_df.loc[all_data_df['gpr_dF/F0'] > 10, 'unique_cell_id'].unique()\n",
    "\n",
    "# Remove all rows for those cells\n",
    "\n",
    "all_data_max_value_filtered_df = all_data_df[~all_data_df['unique_cell_id'].isin(cells_to_remove)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for frames after the 15th (i.e., frame > 15)\n",
    "after_15_df = all_data_max_value_filtered_df[all_data_max_value_filtered_df['frame'] > 15]\n",
    "\n",
    "# Find unique_cell_id that reach threshold at any point after frame 15\n",
    "cells_with_peak = after_15_df[after_15_df['gpr_dF/F0'] >= 0.5]['unique_cell_id'].unique()\n",
    "\n",
    "# Keep only those cells in the dataframe\n",
    "max_and_min_filtered_df = all_data_max_value_filtered_df[all_data_max_value_filtered_df['unique_cell_id'].isin(cells_with_peak)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb3fc38",
   "metadata": {},
   "source": [
    "CLUSTERING DATA INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fda809",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_clustering = max_and_min_filtered_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_cols=[\"time\",\"gpr_dF/F0\"]\n",
    "mySeriesData=[]\n",
    "mySeriesName=[]\n",
    "null_cell = []\n",
    "\n",
    "print(len(data_for_clustering[\"unique_cell_id\"].unique()))\n",
    "\n",
    "for u_cell in data_for_clustering[\"unique_cell_id\"].unique():\n",
    "    data_curr = data_for_clustering[data_for_clustering.unique_cell_id==u_cell][needed_cols].copy()\n",
    "    data_curr.columns =[\"time\",\"value\"]\n",
    "    if any(data_curr[\"value\"].isnull()):\n",
    "        null_cell.append(u_cell)\n",
    "        continue\n",
    "    \n",
    "    mySeriesData.append(data_curr.set_index(\"time\"))\n",
    "    mySeriesName.append(u_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what unique time series lengths are in mySeriesData\n",
    "unique_lengths = set(len(series) for series in mySeriesData)\n",
    "print(f\"Unique time series lengths in mySeriesData: {unique_lengths}\")\n",
    "\n",
    "#print all unique time series lengths\n",
    "for length in unique_lengths:\n",
    "    print(f\"Time series length: {length} - Number of cells: {sum(len(series) == length for series in mySeriesData)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f908e",
   "metadata": {},
   "source": [
    "Normalizing data before clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c035c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeries=[]\n",
    "for i in range(len(mySeriesData)):\n",
    "    scaler = MinMaxScaler()\n",
    "    curr = MinMaxScaler().fit_transform(mySeriesData[i])\n",
    "    mySeries.append(curr.reshape(len(curr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907901fe",
   "metadata": {},
   "source": [
    "ACTUAL MINISOM CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8897b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "som_x = 2\n",
    "som_y = 2\n",
    "som = MiniSom(som_x, som_y, len(mySeries[0]), sigma=0.3, learning_rate=0.5, random_seed=42)\n",
    "\n",
    "som.random_weights_init(mySeries)\n",
    "som.train(mySeries, 50000, use_epochs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b7bfa",
   "metadata": {},
   "source": [
    "MAPPING CLUSTER NUMBERS TO CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c16ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign each cell to a cluster\n",
    "cluster_assignments = []\n",
    "for i, series in enumerate(mySeries):\n",
    "    winner = som.winner(series)  # (x, y) coordinates of the winning node\n",
    "    cluster_assignments.append({'unique_cell_id': mySeriesName[i], 'cluster_x': winner[0], 'cluster_y': winner[1]})\n",
    "\n",
    "# Convert to DataFrame\n",
    "cluster_df = pd.DataFrame(cluster_assignments)\n",
    "\n",
    "# Save to CSV\n",
    "cluster_df.to_csv(r'', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd4417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = []\n",
    "for idx in range(len(mySeries)):\n",
    "    winner_node = som.winner(mySeries[idx])\n",
    "    cluster_map.append((mySeriesName[idx],f\"Cluster {winner_node[0]*som_y+winner_node[1]+1}\"))\n",
    "\n",
    "name_cluster= pd.DataFrame(cluster_map,columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sixteen_cluster_dataframe = data_for_clustering.merge(name_cluster,left_on =\"unique_cell_id\",right_on=\"Series\",how=\"left\")\n",
    "\n",
    "display(sixteen_cluster_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e8f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sixteen_cluster_dataframe.to_csv(r'', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
